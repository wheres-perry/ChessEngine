{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd9c0b3",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccad84d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import chess\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad89d82",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd1a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../../'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Attempt to import create_tensor\n",
    "try:\n",
    "    from src.io.to_tensor import create_tensor \n",
    "except ImportError:\n",
    "    print(f\"Error: Could not import create_tensor from src.io.to_tensor.\")\n",
    "    print(f\"Ensure 'src' directory is in sys.path ('{project_root}' was added) and contains io/to_tensor.py.\")\n",
    "    print(f\"Current sys.path includes: {sys.path[:3]} ...\") # \n",
    "    pass\n",
    "\n",
    "\n",
    "# Configuration\n",
    "FILE_PATH = \"../../data/raw/lichess_eval/lichess_db_eval.jsonl\"\n",
    "OUTPUT_DIR = '../../data/processed/lichess_eval/'\n",
    "BATCH_SIZE = 1_000_000  \n",
    "MAX_CP = 2000.0  \n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b465b1d",
   "metadata": {},
   "source": [
    " ### Processing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdeabec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing of: ../../data/raw/lichess_eval/lichess_db_eval.jsonl\n",
      "Saving processed tensors in batches of 1000000 to: ../../data/processed/lichess_eval/\n"
     ]
    }
   ],
   "source": [
    "batch_num = 0\n",
    "entries_in_current_batch = 0\n",
    "tensors_batch = []\n",
    "labels_batch = []\n",
    "total_valid_entries_processed = 0\n",
    "lines_read = 0\n",
    "\n",
    "print(f\"Starting processing of: {FILE_PATH}\")\n",
    "print(f\"Saving processed tensors in batches of {BATCH_SIZE} to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814f878d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONL file: 1208241lines [14:00, 1462.86lines/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved batch 1 to ../../data/processed/lichess_eval/1.pt. Inputs shape: torch.Size([1000000, 28, 8, 8]), Labels shape: torch.Size([1000000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONL file: 2390633lines [27:20, 1418.24lines/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved batch 2 to ../../data/processed/lichess_eval/2.pt. Inputs shape: torch.Size([1000000, 28, 8, 8]), Labels shape: torch.Size([1000000, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONL file: 3131992lines [37:17, 1399.50lines/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m cp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m         board = \u001b[43mchess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mBoard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m         tensor = create_tensor(board)\n\u001b[32m     21\u001b[39m         clipped_cp = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmin\u001b[39m(cp, MAX_CP), -MAX_CP)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/chess/__init__.py:1711\u001b[39m, in \u001b[36mBoard.__init__\u001b[39m\u001b[34m(self, fen, chess960)\u001b[39m\n\u001b[32m   1709\u001b[39m     \u001b[38;5;28mself\u001b[39m.reset()\n\u001b[32m   1710\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1711\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mset_fen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfen\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/chess/__init__.py:2646\u001b[39m, in \u001b[36mBoard.set_fen\u001b[39m\u001b[34m(self, fen)\u001b[39m\n\u001b[32m   2643\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfen string has more parts than expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfen\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   2645\u001b[39m \u001b[38;5;66;03m# Validate the board part and set it.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_board_fen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard_part\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[38;5;66;03m# Apply.\u001b[39;00m\n\u001b[32m   2649\u001b[39m \u001b[38;5;28mself\u001b[39m.turn = turn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.13/site-packages/chess/__init__.py:1173\u001b[39m, in \u001b[36mBaseBoard._set_board_fen\u001b[39m\u001b[34m(self, fen)\u001b[39m\n\u001b[32m   1171\u001b[39m     piece = Piece.from_symbol(c)\n\u001b[32m   1172\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_piece_at(SQUARES_180[square_index], piece.piece_type, piece.color)\n\u001b[32m-> \u001b[39m\u001b[32m1173\u001b[39m     square_index += \u001b[32m1\u001b[39m\n\u001b[32m   1174\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m c == \u001b[33m\"\u001b[39m\u001b[33m~\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1175\u001b[39m     \u001b[38;5;28mself\u001b[39m.promoted |= BB_SQUARES[SQUARES_180[square_index - \u001b[32m1\u001b[39m]]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(FILE_PATH, 'r') as file:\n",
    "        for line in tqdm(file, desc=\"Processing JSONL file\", unit=\"lines\"):\n",
    "            lines_read += 1\n",
    "            try:\n",
    "                obj = json.loads(line.strip())\n",
    "                fen = obj.get('fen')\n",
    "                cp = None\n",
    "\n",
    "                if obj.get('evals') and len(obj['evals']) > 0:\n",
    "                    if obj['evals'][0].get('pvs') and len(obj['evals'][0]['pvs']) > 0:\n",
    "                        cp_value = obj['evals'][0]['pvs'][0].get('cp')\n",
    "                        if cp_value is not None:\n",
    "                            cp = int(cp_value)\n",
    "\n",
    "                if fen is not None and cp is not None:\n",
    "                    try:\n",
    "                        board = chess.Board(fen)\n",
    "                        tensor = create_tensor(board)\n",
    "                        \n",
    "                        clipped_cp = max(min(cp, MAX_CP), -MAX_CP)\n",
    "                        normalized_label = clipped_cp / MAX_CP\n",
    "                        \n",
    "                        tensors_batch.append(tensor)\n",
    "                        labels_batch.append(normalized_label)\n",
    "                        entries_in_current_batch += 1\n",
    "                        total_valid_entries_processed += 1\n",
    "\n",
    "                    except ValueError as e:\n",
    "                        # print(f\"Skipping invalid FEN on line {lines_read} ('{fen}'): {e}\")\n",
    "                        pass \n",
    "                    except Exception as e:\n",
    "                        # print(f\"Error processing FEN on line {lines_read} ('{fen}'): {e}\")\n",
    "                        pass\n",
    "\n",
    "                if entries_in_current_batch >= BATCH_SIZE:\n",
    "                    if tensors_batch:\n",
    "                        input_tensors = torch.stack(tensors_batch)\n",
    "                        label_tensors = torch.tensor(labels_batch, dtype=torch.float32).unsqueeze(1)\n",
    "                        \n",
    "                        processed_data_batch = {'inputs': input_tensors, 'labels': label_tensors}\n",
    "                        output_tensor_path = os.path.join(OUTPUT_DIR, f'{batch_num + 1}.pt')\n",
    "                        torch.save(processed_data_batch, output_tensor_path)\n",
    "                        print(f\"\\nSaved batch {batch_num + 1} to {output_tensor_path}. \"\n",
    "                              f\"Inputs shape: {input_tensors.shape}, Labels shape: {label_tensors.shape}\")\n",
    "\n",
    "                        tensors_batch = []\n",
    "                        labels_batch = []\n",
    "                        entries_in_current_batch = 0\n",
    "                        batch_num += 1\n",
    "                    else:\n",
    "                        # print(f\"\\nWarning: Batch {batch_num + 1} was marked full but no tensors collected.\")\n",
    "                        pass # Also hiding this warning as per general request to hide errors/warnings\n",
    "\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # print(f\"Skipping line {lines_read} due to JSON decode error: {line.strip()}\")\n",
    "                pass\n",
    "            except Exception as e: \n",
    "                # print(f\"Skipping line {lines_read} due to an unexpected error: {e} - Line: {line.strip()}\")\n",
    "                pass\n",
    "\n",
    "    if tensors_batch: \n",
    "        input_tensors = torch.stack(tensors_batch)\n",
    "        label_tensors = torch.tensor(labels_batch, dtype=torch.float32).unsqueeze(1)\n",
    "        \n",
    "        processed_data_batch = {'inputs': input_tensors, 'labels': label_tensors}\n",
    "        output_tensor_path = os.path.join(OUTPUT_DIR, f'{batch_num + 1}.pt')\n",
    "        torch.save(processed_data_batch, output_tensor_path)\n",
    "        print(f\"\\nSaved final batch {batch_num + 1} to {output_tensor_path}. \"\n",
    "              f\"Inputs shape: {input_tensors.shape}, Labels shape: {label_tensors.shape}\")\n",
    "    elif total_valid_entries_processed == 0:\n",
    "        print(\"\\nNo valid data processed from the file. No .pt files were created.\")\n",
    "    else:\n",
    "        print(\"\\nFinished processing. No remaining data for a final partial batch, or the last batch was empty.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {FILE_PATH} was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during file processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97291418",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Processing Summary ---\")\n",
    "print(f\"Total lines read from file: {lines_read}\")\n",
    "print(f\"Total valid entries processed and saved: {total_valid_entries_processed}\")\n",
    "print(f\"Number of .pt files created: {batch_num + 1 if tensors_batch and total_valid_entries_processed > 0 else batch_num}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(\"Processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
