{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccad84d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import chess\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad89d82",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd1a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../../'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Attempt to import create_tensor\n",
    "try:\n",
    "    from src.io.to_tensor import create_tensor \n",
    "except ImportError:\n",
    "    print(f\"Error: Could not import create_tensor from src.io.to_tensor.\")\n",
    "    print(f\"Ensure 'src' directory is in sys.path ('{project_root}' was added) and contains io/to_tensor.py.\")\n",
    "    print(f\"Current sys.path includes: {sys.path[:3]} ...\") # \n",
    "    pass\n",
    "\n",
    "\n",
    "# Configuration\n",
    "FILE_PATH = \"../../data/raw/lichess_eval/lichess_db_eval.jsonl\"\n",
    "OUTPUT_DIR = '../../data/processed/lichess_eval/'\n",
    "BATCH_SIZE = 1_000_000  \n",
    "MAX_CP = 2000.0  \n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b465b1d",
   "metadata": {},
   "source": [
    " ### Processing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdeabec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing of: ../../data/raw/lichess_eval/lichess_db_eval.jsonl\n",
      "Saving processed tensors in batches of 1000000 to: ../../data/processed/lichess_eval/\n"
     ]
    }
   ],
   "source": [
    "batch_num = 0\n",
    "entries_in_current_batch = 0\n",
    "tensors_batch = []\n",
    "labels_batch = []\n",
    "total_valid_entries_processed = 0\n",
    "lines_read = 0\n",
    "\n",
    "print(f\"Starting processing of: {FILE_PATH}\")\n",
    "print(f\"Saving processed tensors in batches of {BATCH_SIZE} to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814f878d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing JSONL file: 123447lines [01:29, 1376.33lines/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     18\u001b[39m     board = chess.Board(fen)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     tensor = \u001b[43mcreate_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     clipped_cp = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmin\u001b[39m(cp, MAX_CP), -MAX_CP)\n\u001b[32m     22\u001b[39m     normalized_label = clipped_cp / MAX_CP\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ethan\\git\\ChessEngine\\src\\io\\to_tensor.py:194\u001b[39m, in \u001b[36mcreate_tensor\u001b[39m\u001b[34m(board)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# Index 21: White attack (Pieces attacked by white)\u001b[39;00m\n\u001b[32m    193\u001b[39m logger.debug(\u001b[33m\"\u001b[39m\u001b[33mAdding white attack plane\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m out[idx] = \u001b[43mcreate_attacked_squares_plane\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mWHITE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m idx += \u001b[32m1\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;66;03m# Index 22: Black attack (Pieces attacked by black)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ethan\\git\\ChessEngine\\src\\io\\to_tensor.py:104\u001b[39m, in \u001b[36mcreate_attacked_squares_plane\u001b[39m\u001b[34m(board, color)\u001b[39m\n\u001b[32m    102\u001b[39m         r = \u001b[32m7\u001b[39m - (i // \u001b[32m8\u001b[39m)\n\u001b[32m    103\u001b[39m         c = i % \u001b[32m8\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m         attack_plane[r, c] = \u001b[32m1.0\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attack_plane\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(FILE_PATH, 'r') as file:\n",
    "        for line in tqdm(file, desc=\"Processing JSONL file\", unit=\"lines\"):\n",
    "            lines_read += 1\n",
    "            try:\n",
    "                obj = json.loads(line.strip())\n",
    "                fen = obj.get('fen')\n",
    "                cp = None\n",
    "\n",
    "                if obj.get('evals') and len(obj['evals']) > 0:\n",
    "                    if obj['evals'][0].get('pvs') and len(obj['evals'][0]['pvs']) > 0:\n",
    "                        cp_value = obj['evals'][0]['pvs'][0].get('cp')\n",
    "                        if cp_value is not None:\n",
    "                            cp = int(cp_value)\n",
    "\n",
    "                if fen is not None and cp is not None:\n",
    "                    try:\n",
    "                        board = chess.Board(fen)\n",
    "                        tensor = create_tensor(board)\n",
    "                        \n",
    "                        clipped_cp = max(min(cp, MAX_CP), -MAX_CP)\n",
    "                        normalized_label = clipped_cp / MAX_CP\n",
    "                        \n",
    "                        tensors_batch.append(tensor)\n",
    "                        labels_batch.append(normalized_label)\n",
    "                        entries_in_current_batch += 1\n",
    "                        total_valid_entries_processed += 1\n",
    "\n",
    "                    except ValueError as e:\n",
    "                        # print(f\"Skipping invalid FEN on line {lines_read} ('{fen}'): {e}\")\n",
    "                        pass \n",
    "                    except Exception as e:\n",
    "                        # print(f\"Error processing FEN on line {lines_read} ('{fen}'): {e}\")\n",
    "                        pass\n",
    "\n",
    "                if entries_in_current_batch >= BATCH_SIZE:\n",
    "                    if tensors_batch:\n",
    "                        input_tensors = torch.stack(tensors_batch)\n",
    "                        label_tensors = torch.tensor(labels_batch, dtype=torch.float32).unsqueeze(1)\n",
    "                        \n",
    "                        processed_data_batch = {'inputs': input_tensors, 'labels': label_tensors}\n",
    "                        output_tensor_path = os.path.join(OUTPUT_DIR, f'{batch_num + 1}.pt')\n",
    "                        torch.save(processed_data_batch, output_tensor_path)\n",
    "                        print(f\"\\nSaved batch {batch_num + 1} to {output_tensor_path}. \"\n",
    "                              f\"Inputs shape: {input_tensors.shape}, Labels shape: {label_tensors.shape}\")\n",
    "\n",
    "                        tensors_batch = []\n",
    "                        labels_batch = []\n",
    "                        entries_in_current_batch = 0\n",
    "                        batch_num += 1\n",
    "                    else:\n",
    "                        # print(f\"\\nWarning: Batch {batch_num + 1} was marked full but no tensors collected.\")\n",
    "                        pass \n",
    "\n",
    "\n",
    "            except json.JSONDecodeError:\n",
    "                # print(f\"Skipping line {lines_read} due to JSON decode error: {line.strip()}\")\n",
    "                pass\n",
    "            except Exception as e: \n",
    "                # print(f\"Skipping line {lines_read} due to an unexpected error: {e} - Line: {line.strip()}\")\n",
    "                pass\n",
    "\n",
    "    if tensors_batch: \n",
    "        input_tensors = torch.stack(tensors_batch)\n",
    "        label_tensors = torch.tensor(labels_batch, dtype=torch.float32).unsqueeze(1)\n",
    "        \n",
    "        processed_data_batch = {'inputs': input_tensors, 'labels': label_tensors}\n",
    "        output_tensor_path = os.path.join(OUTPUT_DIR, f'{batch_num + 1}.pt')\n",
    "        torch.save(processed_data_batch, output_tensor_path)\n",
    "        print(f\"\\nSaved final batch {batch_num + 1} to {output_tensor_path}. \"\n",
    "              f\"Inputs shape: {input_tensors.shape}, Labels shape: {label_tensors.shape}\")\n",
    "    elif total_valid_entries_processed == 0:\n",
    "        print(\"\\nNo valid data processed from the file. No .pt files were created.\")\n",
    "    else:\n",
    "        print(\"\\nFinished processing. No remaining data for a final partial batch, or the last batch was empty.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {FILE_PATH} was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during file processing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97291418",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Processing Summary ---\")\n",
    "print(f\"Total lines read from file: {lines_read}\")\n",
    "print(f\"Total valid entries processed and saved: {total_valid_entries_processed}\")\n",
    "print(f\"Number of .pt files created: {batch_num + 1 if tensors_batch and total_valid_entries_processed > 0 else batch_num}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(\"Processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chessengine-X4VeOdRz-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
