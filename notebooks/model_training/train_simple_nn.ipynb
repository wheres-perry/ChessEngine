{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Training Notebook for ChessNN\n",
    "\n",
    "\n",
    "\n",
    " This notebook trains the `ChessNN` model from `simple_nn_eval.py` using processed data from `lichess_processed.pt`.\n",
    "\n",
    "\n",
    "\n",
    " **Key Techniques**:\n",
    "\n",
    " - **Data Handling**: Load tensors, split into train/validation (80/20), use `DataLoader` for batching.\n",
    "\n",
    " - **Model**: Use `ChessNN` for regression (predict normalized CP scores).\n",
    "\n",
    " - **Training**: MSE loss, Adam optimizer, learning rate scheduler, early stopping to prevent overfitting.\n",
    "\n",
    " - **Hardware**: GPU support if available.\n",
    "\n",
    " - **Logging**: Track loss, save best model.\n",
    "\n",
    " - **Assumptions**: Data is pre-processed (FEN -> tensors, normalized labels in [-1, 1]).\n",
    "\n",
    "\n",
    "\n",
    " **Requirements**: Run after processing in `process_lichess_evals.ipynb`. Install `torch`, `chess`, `tqdm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loaded 99365 samples. Inputs shape: torch.Size([99365, 28, 8, 8]), Labels shape: torch.Size([99365, 1])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m criterion = nn.MSELoss()  \u001b[38;5;66;03m# Suitable for regression\u001b[39;00m\n\u001b[32m     45\u001b[39m optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m scheduler = \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mReduceLROnPlateau\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Training function with early stopping\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtrain_model\u001b[39m():\n",
      "\u001b[31mTypeError\u001b[39m: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from src.engine.evaluators.simple_nn_eval import ChessNN  # Import the model class\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = '../../data/processed/lichess_eval/lichess_processed.pt'  # From processing step\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "PATIENCE = 5  # For early stopping\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Load processed data\n",
    "data = torch.load(DATA_PATH)\n",
    "inputs = data['inputs'].to(DEVICE)  # Shape: [num_samples, NUM_PLANES, 8, 8]\n",
    "labels = data['labels'].to(DEVICE)  # Shape: [num_samples, 1]\n",
    "print(f\"Loaded {len(inputs)} samples. Inputs shape: {inputs.shape}, Labels shape: {labels.shape}\")\n",
    "\n",
    "# Create dataset and split (80% train, 20% validation)\n",
    "dataset = TensorDataset(inputs, labels)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "model = ChessNN().to(DEVICE)\n",
    "criterion = nn.MSELoss()  # Suitable for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, verbose=True)\n",
    "\n",
    "# Training function with early stopping\n",
    "def train_model():\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_losses, val_losses = [], []\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        # Train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_inputs, batch_labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} - Training\"):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_inputs)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_inputs, batch_labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} - Validation\"):\n",
    "                outputs = model(batch_inputs)\n",
    "                loss = criterion(outputs, batch_labels)\n",
    "                val_loss += loss.item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_chess_nn.pth')\n",
    "            print(\"Saved best model.\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= PATIENCE:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "    \n",
    "    # Plot losses\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()\n",
    "\n",
    "# Run training\n",
    "train_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Post-Training Notes\n",
    "\n",
    " - **Model Saving**: The best model is saved as `best_chess_nn.pth`. Load it in `simple_nn_eval.py` using `model.load_state_dict(torch.load('best_chess_nn.pth'))`.\n",
    "\n",
    " - **Evaluation**: The model predicts normalized scores [-1, 1], which are scaled back in `evaluate()` of `simple_nn_eval.py`.\n",
    "\n",
    " - **Improvements**: For larger datasets, consider distributed training or gradient accumulation. Monitor for overfitting via the loss plot.\n",
    "\n",
    " - **Testing**: After training, test with a sample board in `simple_nn_eval.py` to verify."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chessengine-wsEd-T9L-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
